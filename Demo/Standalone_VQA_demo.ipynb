{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Standalone_VQA_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mtw_vpWYToK",
        "colab_type": "text"
      },
      "source": [
        "# VQA Demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsrr7dlsX239",
        "colab_type": "text"
      },
      "source": [
        "# Imports and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AMk0oqXXugO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c11354a-4f7f-4f61-e1f0-f94fe9e7ec2b"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML, Image\n",
        "import IPython\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image, display, clear_output\n",
        "import json\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import os\n",
        "import importlib.util\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from collections import Counter\n",
        "tf.enable_eager_execution()\n",
        "import cv2\n",
        "import time\n",
        "from keras import regularizers\n",
        "from keras.models import load_model\n",
        "import time\n",
        "\n",
        "demo_root = ''\n",
        "videoPath = os.path.join(demo_root, 'video.mp4')\n",
        "photoPath = os.path.join(demo_root, 'photo.jpg')\n",
        "train_questions_file = os.path.join(demo_root,'v2_OpenEnded_mscoco_train2014_questions.json')\n",
        "train_answers_file = os.path.join(demo_root,'v2_mscoco_train2014_annotations.json')\n",
        "glove_file_path =  os.path.join(demo_root,'glove.6B.300d.txt')\n",
        "pretrained_model_path = os.path.join(demo_root, 'pretrainedModel.h5')\n",
        "SENTENCE_SPLIT_REGEX = re.compile(r'(\\W+)')\n",
        "\n",
        "MAX_LEN = 14\n",
        "FILL_TOKEN = 'FILL_TOKEN'\n",
        "ANSWER_OCCURENCE_MIN = 15\n",
        "ANSWER_DIM = 0\n",
        "IMAGE_NON_LINEAR_OUTPUT_DIM = TEXT_NON_LINEAR_OUTPUT_DIM = 512\n",
        "WORD_EMBEDDING_DIM = 300\n",
        "num_occurence = 5\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr3LJD_QYluP",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive (if you use it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjtVIiuxYu0H",
        "colab_type": "code",
        "outputId": "31377857-c2ba-405f-d342-e3b08d1a30c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive_root = '/content/gdrive'\n",
        "drive.mount(drive_root)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldDsVbshRGwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, HTML, Javascript\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image, display, clear_output\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<video autoplay\n",
        " width=800 height=600></video>\n",
        "<script>\n",
        "var video = document.querySelector('video')\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "var button = document.querySelector('button')\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "def testphoto(videoPath = '/content/video.mp4', filename='/content/photo.jpg') :\n",
        "  video = io.open(videoPath, 'r+b').read()\n",
        "  encoded = base64.b64encode(video)\n",
        "  x = '''<video  controls autoplay width=800 height=600 >\n",
        "                <source src=\"data:video/mp4;base64,'''+str(encoded.decode('ascii'))+''' \" type=\"video/mp4\" />\n",
        "             </video>\n",
        "             <button id =\"but\" type=\"button\">take screen</button>\n",
        "               <script>\n",
        "             \n",
        "    var video = document.querySelector('video')\n",
        "    var button = document.getElementById(\"but\");\n",
        "    \n",
        "   var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "\tconsole.log('hhhhhhhhheeeeeeloooooo')\n",
        "    var canvas = document.createElement('canvas')\n",
        "\tcanvas.crossOrigin=\"anonymous\"\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    //video.srcObject.getVideoTracks()[0].stop()\n",
        "\tvideo.pause()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', '%f'))\n",
        "  }\n",
        "})\n",
        "    </script>'''\n",
        "  \n",
        "  display(HTML(x % 0.8) )\n",
        "  current = os.getcwd()\n",
        "  os.chdir('/content')\n",
        "  #display(HTML(VIDEO_HTML2 % quality))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  os.chdir(current)\n",
        "  return binary\n",
        "  \n",
        "def take_photo(source, filename=photoPath, quality = 0.8):\n",
        "  VIDEO_HTML2 = \"\"\"\n",
        "    <video controls  alt=\"test\" width=800 height=600 autoplay >\n",
        "      <source src=\"/content/video.mp4\" type=\"video/mp4\">\n",
        "      Sorry, not displaying\n",
        "     </video>\n",
        "     <script>\n",
        "    var video = document.querySelector('video')\n",
        "    //console.log(video)\n",
        "    video.play(); \n",
        "    var data = new Promise(resolve=>{\n",
        "      video.onclick = ()=>{\n",
        "        var canvas = document.createElement('canvas')\n",
        "        var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "        canvas.width = w\n",
        "        canvas.height = h\n",
        "        canvas.getContext('2d')\n",
        "              .drawImage(video, 0, 0, w, h)\n",
        "        video.srcObject.getVideoTracks()[0].stop()\n",
        "        video.replaceWith(canvas)\n",
        "        resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "      }\n",
        "    })\n",
        "    </script>\n",
        "    \n",
        "  \"\"\"\n",
        "  \n",
        "  ss = \"\"\"\n",
        "  \"\"\"\n",
        "  current = os.getcwd()\n",
        "  os.chdir(root_root)\n",
        "  display(HTML(VIDEO_HTML2 % quality))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  os.chdir(current)\n",
        "  return binary\n",
        "\n",
        "def take_photo_live(filename=photoPath, quality=0.8):\n",
        "  clear_output()\n",
        "  display(HTML(VIDEO_HTML % quality))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return binary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UCfXguv1l8eb",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def take_photo_live(filename=photoPath, quality=0.8):\n",
        "  clear_output()\n",
        "  display(HTML(VIDEO_HTML % quality))\n",
        "  #data = display(IPython.display.Javascript(data))\n",
        "  #data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return binary\n",
        "\n",
        "def get_uploaded_image() :\n",
        "  current = os.getcwd()\n",
        "  os.chdir(demo_root)\n",
        "  t = False  \n",
        "  uploaded = files.upload()      \n",
        "  if not uploaded :\n",
        "    return None\n",
        "  im_path = os.path.join(demo_root,list(uploaded.keys())[0])\n",
        "  clear_output()\n",
        "  display(Image(filename= im_path, width=700, height=500))\n",
        "  os.chdir(current)\n",
        "  return im_path\n",
        "\n",
        "def get_uploaded_video() :\n",
        "  current = os.getcwd()\n",
        "  os.chdir(demo_root)\n",
        "  t = False\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  if not uploaded :\n",
        "    return None\n",
        "  im_path = os.path.join(demo_root,list(uploaded.keys())[0])\n",
        "  clear_output()\n",
        "  os.chdir(current)\n",
        "  return im_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_jWyr8zXibb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "dfc989fe-7f4d-4ce1-e718-e3b2ff1e4099"
      },
      "source": [
        "\n",
        "class QuestionsPreprocessing : \n",
        "  \n",
        "  def __init__(self, glove_file, questions_files, num_occurence) :\n",
        "    self.gloveFile  = glove_file\n",
        "    self.questionsFiles = questions_files\n",
        "    self.word2Glove = self.readGloveFile()\n",
        "    questions = self.readQuestionsFiles()\n",
        "    self.questions_files = questions_files\n",
        "    #filter words that have occurence less than occurence\n",
        "    words = self.filter_words(questions,num_occurence)\n",
        "    #partition words from weather they are in glove or not\n",
        "    self.word2Index, self.index2Word = self.matchWordIndex(words)\n",
        "    #consider the 0 padding\n",
        "    self.vocab_length = len(self.word2Index) + 1 \n",
        "     \n",
        "    \n",
        "  def readGloveFile(self):\n",
        "      with open(self.gloveFile, 'r') as f:\n",
        "          wordToGlove = {}  # map from a token (word) to a Glove embedding vector\n",
        "          #wordToIndex = {}  # map from a token to an index\n",
        "          #indexToWord = {}  # map from an index to a token \n",
        "\n",
        "          for line in f:\n",
        "              record = line.strip().split()\n",
        "              token = record[0] # take the token (word) from the text line\n",
        "              wordToGlove[token] = np.array(record[1:], dtype=np.float64) # associate the Glove embedding vector to a that token (word)\n",
        "\n",
        "      return wordToGlove\n",
        "    \n",
        "  #return all words in questions\n",
        "  #WARNING IMPORTANT : THIS FUNCTION IS ONLY FOR RETRIEVING QUESTIONS FROM VQA DATASET\n",
        "  def readQuestionsFiles(self) : \n",
        "    questions = []\n",
        "    for file in self.questionsFiles :\n",
        "      with open(file, 'r') as f : \n",
        "        data = json.load(f)\n",
        "        for x in data['questions']:\n",
        "          questions.append(x['question'])\n",
        "    return questions    \n",
        "        \n",
        "    \n",
        "  def filter_words(self,questions, num_occurence):\n",
        "    words = {}\n",
        "    for question in questions : \n",
        "      for word in tokenize(question):\n",
        "        if(word in words):\n",
        "          words[word] +=1\n",
        "        else :\n",
        "          words[word] = 1\n",
        "    return [k for k,v in words.items() if v > num_occurence]\n",
        "   \n",
        "    \n",
        "  def matchWordIndex(self, words) : \n",
        "    word2Index = {}\n",
        "    index2Word = {}\n",
        "    for i, word in enumerate(words):\n",
        "      word2Index[word] = i+1\n",
        "      index2Word[i+1] =word\n",
        "    return word2Index, index2Word\n",
        "    \n",
        " \n",
        "  # create embedding matrix\n",
        "  def createPretrainedEmbeddingLayer(self):\n",
        "      wordToIndex = self.word2Index\n",
        "      wordToGlove = self.word2Glove\n",
        "      vocabLen = len(wordToIndex) + 1  # adding 1 to account for masking\n",
        "      glove_words = wordToGlove.keys()\n",
        "      embDim = next(iter(wordToGlove.values())).shape[0] \n",
        "      embeddingMatrix = np.zeros((vocabLen, embDim), 'float64')  # initialize with zeros\n",
        "      for word, index in wordToIndex.items():\n",
        "        if word in glove_words:\n",
        "          embeddingMatrix[index, :] = wordToGlove[word] # create embedding: word index to Glove word embedding\n",
        "        else : \n",
        "          embeddingMatrix[index, :] = np.random.rand(1, embDim)\n",
        "      return embeddingMatrix\n",
        "\n",
        "  \n",
        "  def get_embedding_matrix(self) : \n",
        "    \n",
        "    embedding_matrix = self.createPretrainedEmbeddingLayer()\n",
        "    return embedding_matrix\n",
        "  \n",
        "# TODO : check if there is another method like removing most common words  \n",
        "  def preprocessBatch(self,questions, max_len):\n",
        "    batch = []\n",
        "    for question in questions : \n",
        "      words =self.preprocessElem(question)\n",
        "      batch.append(num_words)\n",
        "    return self.postTruncate(batch, max_len)\n",
        "\n",
        "  def preprocessElem(self,question):\n",
        "    words = self.preTruncate(question)\n",
        "    words = tokenize(words)\n",
        "    num_words = []\n",
        "    for word in words :\n",
        "      w = self.word2Index.get(word, 'not_found_word')\n",
        "      if not w is 'not_found_word' :\n",
        "        num_words.append(w)\n",
        "    return num_words\n",
        "  #private\n",
        "  #TODO : implement\n",
        "  def preTruncate(self, words): \n",
        "    return words\n",
        "  \n",
        "  def postTruncate(self,batch, max_len) : \n",
        "    return  keras.preprocessing.sequence.pad_sequences(batch, max_len,padding ='post', truncating = 'post')\n",
        "    \n",
        "    \n",
        "class AnswerPreprocessing : \n",
        "  def __init__(self, questions_files, answers_files):\n",
        "    global ANSWER_DIM\n",
        "    assert len(questions_files) == len(answers_files), 'not the same length'\n",
        "    self.answers, _ = self.get_answers(questions_files[0], answers_files[0])\n",
        "    #for i, f in enumerate(questions_files):\n",
        "     # s,m = self.get_answers(questions_files[i], answers_files[i])\n",
        "     # self.answers = self.answers.union(s)\n",
        "    self.word2Index = {}\n",
        "    self.index2Word = {}\n",
        "    self.word2Index, self.index2Word = self.matchWords2Indexes()\n",
        "    ANSWER_DIM = len(self.word2Index)\n",
        "    self.num_words = len(self.word2Index)\n",
        "  \n",
        "  def get_dim():\n",
        "    return len(self.word2Index)\n",
        "  #private\n",
        "  def matchWords2Indexes(self): \n",
        "    wordToIndex = {}\n",
        "    indexToWord = {}\n",
        "    words = self.answers\n",
        "    words = self.filterWords(words)\n",
        "    wordToIndex['no idea'] = 0\n",
        "    indexToWord[0] = 'no idea'\n",
        "    i = 1\n",
        "    for w in words:\n",
        "      if not w == 'no idea' :\n",
        "        wordToIndex[w] = i\n",
        "        indexToWord[i] = w\n",
        "        i += 1\n",
        "    return (wordToIndex, indexToWord)\n",
        "  #private\n",
        "  def readWords(self) :\n",
        "    words = []\n",
        "    for file in self.answer_files : \n",
        "      with open(file, 'r') as f : \n",
        "        data = json.load(f)\n",
        "        for annotation in data['annotations'] : \n",
        "          for answer in annotation['answers']:\n",
        "            words.append(answer['answer'])\n",
        "    return words\n",
        "  \n",
        "  #private\n",
        "  def filterWords (self, words) : \n",
        "    return words\n",
        "  \n",
        "  def preprocessBatch(self, answers) : \n",
        "    batch  = []\n",
        "    ans = np.array(answers)\n",
        "    if ans.ndim == 2 : \n",
        "      for answers2 in answers : \n",
        "         batch.append([self.word2Index[x] for x in answers2])\n",
        "    else : \n",
        "      for answer in answers: \n",
        "        batch.append(self.word2Index[answer])\n",
        "    return batch\n",
        " \n",
        "  \n",
        "  def _preprocessElem(self,ans):\n",
        "    # if the dataset contains multiple answers : Exemple VQA dataset\n",
        "    answer = np.array([x for x in ans if not x == FILL_TOKEN])\n",
        "    if answer.ndim == 1 :\n",
        "      arr = np.zeros((ANSWER_DIM,))\n",
        "      if len(answer) == 0 :\n",
        "        arr[0] = 1.0\n",
        "        return arr\n",
        "      else :\n",
        "      #arr = np.zeros(self.num_words,dtype=int)\n",
        "        \n",
        "        value = 1/len(answer)\n",
        "        found = False\n",
        "        for i, a in enumerate(answer):\n",
        "          if a in self.word2Index:\n",
        "            found = True\n",
        "            arr[self.word2Index[a]] += value\n",
        "        if not found :\n",
        "          arr[0] = 1.0\n",
        "        return arr\n",
        "    #if the answer is unique in the dataset\n",
        "    else :\n",
        "      return self.word2Index[answer]\n",
        "    \n",
        "  def preprocessElem(self,ans):\n",
        "    answer = np.array([x for x in ans if not x == FILL_TOKEN], 'str')\n",
        "    arr = np.zeros((ANSWER_DIM,))\n",
        "    if len(answer) == 0 :\n",
        "      arr[0] =1\n",
        "    else :\n",
        "      c = Counter(answer)\n",
        "      t = [x for (x,y) in c.items() if x in self.word2Index]\n",
        "      if t == [] :\n",
        "        arr[0] = 1\n",
        "      else :\n",
        "        for elem, occur in c.items() :\n",
        "          if elem in self.word2Index :\n",
        "            index = self.word2Index[elem]\n",
        "            score = 1 if occur >=3 else 1/3* occur\n",
        "            arr[index] = score\n",
        "    return arr \n",
        "  \n",
        "  def get_ques2(self,questions_file):\n",
        "      with open(questions_file,'r') as f : \n",
        "        data = json.load(f)\n",
        "      questions = data['questions']\n",
        "      qsid_iq = { x['question_id']:  x['question'] for x in questions }\n",
        "      return qsid_iq\n",
        "\n",
        "    \n",
        "  def get_answers( self, questions_file,answers_file) :\n",
        "    global ANSWER_DIM\n",
        "    numbers  = [\"zero\",\"one\",\"two\",\"three\",\"four\",\n",
        "          \"five\",\"six\",\"seven\",\"eight\",\"nine\",\"ten\",\n",
        "          \"eleven\",\"twelve\",\"thirteen\",\"fourteen\",\"fifteen\",\n",
        "          \"sixteen\",\"seventeen\",\"eighteen\",\"nineteen\"];\n",
        "    tens = [\"Twenty\",\"Thirty\",\"Forty\",\"Fifty\",\n",
        "          \"Sixty\",\"Seventy\",\"Eighty\",\"Ninety\"]\n",
        "    id_qs = self.get_ques2(questions_file)\n",
        "\n",
        "    with open(answers_file,'r') as f : \n",
        "      data = json.load(f)\n",
        "    resps = data['annotations']\n",
        "    res = [] \n",
        "    ids = []\n",
        "    conf =[]\n",
        "    for x in resps:\n",
        "      question = id_qs[x['question_id']].strip().lower()\n",
        "      questionID = x['question_id']\n",
        "      ans = [y['answer'].replace(',', ' ').replace('?', '').replace('\\'s', ' \\'s').strip().lower() for y in x['answers'] ]\n",
        "      res1 =[]\n",
        "      for word in ans :\n",
        "          if word == 'no 1' or 'no one' in word :\n",
        "            res1.append('no one')\n",
        "          elif word in ['no clue', \"i dont know\", \"i don't know\", \"cannot know\", \"can't know\", \"can't tell\", \"not sure\", \"don't know\", \"cannot tell\", \"unknown\"]:\n",
        "            res1.append('no idea')\n",
        "          elif word == 'my best guess is no' or \"it isn't\" in word or  'it is not' in word:\n",
        "            res1.append('no')\n",
        "          elif 'many' in word or 'several' in word or 'lot' in word or 'numerous' in word:\n",
        "            res1.append('many')\n",
        "          elif word in numbers :\n",
        "            res1.append(str(numbers.index(word)))\n",
        "          elif word in tens:\n",
        "            res1.append(str((ten.index(word) + 2) * 10))\n",
        "          else :\n",
        "            res1.append(word)\n",
        "\n",
        "\n",
        "\n",
        "      if question.startswith('how many') or question.startswith('what is the number'):\n",
        "        for word in res1 :\n",
        "          if re.search('(\\s|^)no ', word) or re.search(' no(\\s|$)',word):\n",
        "            if word == 'no idea':\n",
        "              res.append('no idea')        \n",
        "            else :\n",
        "              res.append('0')\n",
        "          elif word == 'o' :\n",
        "            res.append(0)\n",
        "          elif not len(re.findall('\\d+', word)) == 0:\n",
        "              res.append(re.findall('\\d+', word)[0])         \n",
        "          elif word == 'no' :\n",
        "              res.append('0')\n",
        "          elif word =='yes' :\n",
        "              res.append('1')\n",
        "          else :\n",
        "              res.append(word)\n",
        "\n",
        "      elif question.startswith('is') or question.startswith('are'):\n",
        "\n",
        "        for word in res1 :\n",
        "          if re.search('(\\s|^)no ', word) or re.search(' no(\\s|$)',word):\n",
        "            res.append('no')\n",
        "          elif word == 'it is' or 'yes' in word:\n",
        "            res.append('yes')\n",
        "          elif 'it is' in word :\n",
        "            s = word.replace('it is', '').strip()\n",
        "            res.append(s)\n",
        "            continue\n",
        "          else :\n",
        "            res.append(word) \n",
        "\n",
        "      else :\n",
        "        for word in res1 :\n",
        "          if word == 'it is' or 'yes' in word:\n",
        "              res.append('yes')\n",
        "          elif 'it is' in word :\n",
        "            s = word.replace('it is', '').strip()\n",
        "            res.append(s)\n",
        "          elif ('there is no' in word) or (\"there's no\" in word) or ('there are no' in word):\n",
        "            res.append('not found')\n",
        "          elif word.strip().startswith('no ') :\n",
        "            ans_tokens = tokenize(word[2:])\n",
        "            ques_tokens = tokenize(question)\n",
        "            boo = True\n",
        "            for t in ans_tokens:\n",
        "              if not (t in ques_tokens or t+'s' in ques_tokens):\n",
        "                boo = False\n",
        "                break\n",
        "            if boo :\n",
        "              res.append('not found')\n",
        "            else :\n",
        "              res.append(word)\n",
        "          else :\n",
        "            res.append(word)  \n",
        "\n",
        "      for s in ans:\n",
        "        ids.append(questionID)\n",
        "\n",
        "      #TODO remove this:    \n",
        "      conf1 = [y['answer_confidence'] for y in x['answers'] ]\n",
        "      conf.extend(conf1)\n",
        "\n",
        "    newres = []\n",
        "    newids = []\n",
        "    for index in range(len(res)) :\n",
        "      if conf[index] == 'yes' :\n",
        "        newres.append(res[index])\n",
        "        newids.append(ids[index])\n",
        "    c = Counter(newres)\n",
        "    resset = set([k for k,v in c.items() if v >= ANSWER_OCCURENCE_MIN])\n",
        "    m = {}\n",
        "    for index in range(len(newres)) :\n",
        "      qid = newids[index]\n",
        "      response = newres[index]\n",
        "      if  response in resset : \n",
        "        if qid in m :\n",
        "          m[qid].append(response)\n",
        "        else :\n",
        "          m[qid] = [response]\n",
        "  #  queskeys = set(ques.keys())\n",
        "\n",
        "   # m = {k : v for k,v in m.items() if k in queskeys} \n",
        "    return resset, m\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def tokenize(sentence):\n",
        "    sentence = sentence.strip().lower()\n",
        "    sentence = (\n",
        "        sentence.replace(',', '').replace('?', '').replace('\\'s', ' \\'s'))\n",
        "    tokens = SENTENCE_SPLIT_REGEX.split(sentence)\n",
        "    tokens = [t.strip() for t in tokens if len(t.strip()) > 0]\n",
        "    return tokens\n",
        "      \n",
        "answer_preprocessor = AnswerPreprocessing([train_questions_file],[train_answers_file])\n",
        "\n",
        "question_preprocessor = QuestionsPreprocessing(glove_file_path, [train_questions_file], num_occurence)\n",
        "\n",
        "\n",
        "question_args = {\n",
        "    \n",
        "    'embedding_size': WORD_EMBEDDING_DIM,\n",
        "    'embedding_weights' : question_preprocessor.get_embedding_matrix(),\n",
        "    'hidden_size' : 512,\n",
        "    'vocab_len' : question_preprocessor.vocab_length,\n",
        "    'num_layers' : 1,\n",
        "    #'dropout' : 0.3\n",
        "    'dropout' : None\n",
        "}\n",
        "text_args = {\n",
        "    'input_shape' : (512,),\n",
        "    'dims' : [1024 ,512],\n",
        "    'activation' : 'relu',\n",
        "    'dropout' : False,\n",
        "    'normalization' : False,\n",
        "    'regularisation' : 0.01\n",
        "}\n",
        "image_args = {\n",
        "    'input_shape' : (2048,),\n",
        "    'dims' : [2048 ,512],\n",
        "    #'dims' : [512],\n",
        "    'activation' : 'relu',\n",
        "    'dropout' : False,\n",
        "    'normalization' : False,\n",
        "    'regularisation' : False\n",
        "}\n",
        "\n",
        "att_args = {\n",
        "    'input_shape' : (512,),\n",
        "    'dims' : [512, 1],\n",
        "    'activation' : 'relu',\n",
        "    'dropout' : False,\n",
        "    'normalization' : False, \n",
        "    'probability_function' : 'softmax',\n",
        "    'regularisation' : 0.01\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "class_args = {\n",
        "    #'input_shape' : (2560,),\n",
        "    'input_shape' : (512,),\n",
        "    'dims' : [ 2048,  ANSWER_DIM],\n",
        "    'activation' : 'relu',\n",
        "    'dropout' : False,\n",
        "    'normalization' : True,\n",
        "    'regularisation' : 0.01\n",
        "}\n",
        "\n",
        "def get_question_module(model_type, kwargs): \n",
        "  if model_type == 'GRU':\n",
        "    return MyGRU(kwargs)\n",
        "  else :\n",
        "    raise NotImplementedError('Unknown question module')\n",
        "\n",
        "\n",
        "\n",
        "class MyGRU(keras.Model) : \n",
        "  def __init__(self, kwargs) :\n",
        "    super(MyGRU, self).__init__()\n",
        "    self.embedding_weights = kwargs['embedding_weights']\n",
        "    self.embedding_size =kwargs['embedding_size']\n",
        "    self.hidden_size = kwargs['hidden_size']\n",
        "    self.num_layers = kwargs['num_layers']\n",
        "    self.vocab_size = kwargs['vocab_len']\n",
        "    tmp_dropout = kwargs['dropout']\n",
        "    self.dropout = tmp_dropout if tmp_dropout else 0.\n",
        "    \n",
        "    #TODO Check trainable\n",
        "    self.embedding = keras.layers.Embedding(input_dim = self.vocab_size,\n",
        "                                            output_dim = self.embedding_size, weights = [self.embedding_weights], trainable = True)\n",
        "    #TODO : see if we use args like : use_bias, activation, initilizers .... see also reset_after\n",
        "    self.seq = keras.models.Sequential()\n",
        "    input_size = self.hidden_size\n",
        "    for i in range(self.num_layers):\n",
        "      self.seq.add(keras.layers.GRU(units = self.hidden_size, dropout = self.dropout, recurrent_dropout= self.dropout))\n",
        "    \n",
        "    \n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)    \n",
        "    x = self.seq(x)\n",
        "    return x\n",
        "    \n",
        "\n",
        "\n",
        "def get_non_linear_function(func_type, kwargs) : \n",
        "  \n",
        "  if func_type == 'activation':\n",
        "    return Activation(kwargs)\n",
        "  else :\n",
        "    raise NotImplementedError('Unknown non linear function')\n",
        "\n",
        "\n",
        "class Activation(keras.Model):\n",
        "  #WARNING must be positive (num_layers), dims size > 1\n",
        "  def __init__(self, kwargs):\n",
        "    super(Activation, self).__init__()\n",
        "    input_shape = kwargs['input_shape']\n",
        "    dims = kwargs['dims']\n",
        "    activation = kwargs['activation']\n",
        "    dropout = kwargs['dropout']\n",
        "    normalization = kwargs['normalization']\n",
        "    regularisation = kwargs['regularisation']\n",
        "    regularisation = regularizers.l2(regularisation) if regularisation else None\n",
        "    \n",
        "    num_layers = len(dims)\n",
        "    self.model = keras.models.Sequential()\n",
        "    for i in range(num_layers- 1):\n",
        "      if input_shape and i == 0 :\n",
        "        self.model.add(keras.layers.Dense(units=dims[i],activation=activation, input_shape = input_shape, kernel_regularizer=regularisation))\n",
        "      else :\n",
        "        self.model.add(keras.layers.Dense(units=dims[i],activation=activation, kernel_regularizer=regularisation))\n",
        "      if normalization :\n",
        "        self.model.add(keras.layers.BatchNormalization())\n",
        "    if dropout:\n",
        "      self.model.add(keras.layers.Dropout(dropout))\n",
        "    self.model.add(keras.layers.Dense(dims[i+1]))\n",
        "    \n",
        "    #TODO : May be we need first dimension if we use this. Done ?\n",
        "    \n",
        "  def call(self,x) :\n",
        "    return self.model(x)\n",
        "\n",
        "class NewModel2(keras.Model) : \n",
        "  def __init__(self,question_args, text_args, image_args, att_args, class_args):\n",
        "    super(NewModel2, self).__init__()\n",
        "    self.text_model =  get_question_module('GRU', question_args)\n",
        "    self.resnet =  keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224,3), pooling=None)\n",
        "    self.text_net = get_non_linear_function('activation', text_args )\n",
        "    self.image_net = get_non_linear_function('activation', image_args ) \n",
        "    self.DImage = keras.layers.Dense(512)\n",
        "    self.merger1 = keras.layers.Multiply()\n",
        "    self.reshape1 = keras.layers.Reshape((7,7,2048))\n",
        "    self.attention_net = get_non_linear_function('activation', att_args) \n",
        "    self.merger2 = keras.layers.Multiply()\n",
        "    self.classifier = get_non_linear_function('activation', class_args) \n",
        "    self.merger3 = keras.layers.Multiply()\n",
        "    self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.1)\n",
        "  \n",
        "  def call(self,images, questions):\n",
        "    timeF = time.time()\n",
        "    images =  self.reshape1(images)\n",
        "    images = tf.math.l2_normalize(images, axis = -1)\n",
        "    questions = self.text_net(questions)\n",
        "    questions_att = tf.keras.backend.expand_dims(\n",
        "      questions,\n",
        "      axis=1)\n",
        "    questions_att = tf.keras.backend.expand_dims(\n",
        "      questions_att,\n",
        "      axis=1)\n",
        "    questions_att = tf.cast(questions_att, tf.float32)\n",
        "    questions_att = tf.keras.backend.tile( questions_att,(1,7,7,1))\n",
        "    att_imgs = self.DImage(images)\n",
        "    common1 = self.merger1([questions, att_imgs])\n",
        "    att_vec = self.attention_net(common1)\n",
        "    att_vec =  tf.keras.backend.tile( att_vec, (1,1,1,2048))\n",
        "    new_imgs = self.merger2([att_vec, images])\n",
        "    new_imgs = tf.reduce_sum(new_imgs, 1) \n",
        "    new_imgs = tf.reduce_sum(new_imgs, 1)\n",
        "    new_imgs = self.image_net(new_imgs)\n",
        "    common2 = self.merger3([new_imgs, questions])\n",
        "    res = self.classifier(common2)\n",
        "    print(\"model call time {}\".format(time.time() - timeF))\n",
        "    return res\n",
        "  \n",
        "  @tf.contrib.eager.defun \n",
        "  def __func(self,tensor,fn):\n",
        "    return tf.map_fn(fn, tensor, parallel_iterations=49)\n",
        "  \n",
        "  def loss(self, result, labels):\n",
        "    loss1 = tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.to_double(result), labels = tf.to_double(labels))\n",
        "    s = loss1.shape[-1]\n",
        "    loss11 = tf.reduce_mean(loss1)\n",
        "    return loss11\n",
        "  \n",
        " \n",
        "    \n",
        "  \n",
        "model = NewModel2(question_args,text_args, image_args, att_args, class_args )\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0831 14:49:31.795946 140593693730688 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BViY-vMdi8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "443068a7-ca00-4963-9878-e71c9f05b791"
      },
      "source": [
        "class Evaluator : \n",
        "  def __init__(self, model, question_preprocessor, answer_preprocessor, weights_path) :\n",
        "    self.resnet =  keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224,3), pooling=None)\n",
        "    self.model = model\n",
        "    self.question_preprocessor = question_preprocessor\n",
        "    self.answer_preprocessor = answer_preprocessor\n",
        "    if os.path.exists(weights_path) and os.path.isfile(weights_path) : \n",
        "      self.model.load_weights(weights_path)\n",
        "    \n",
        "  def evaluate(self, image_path, question) : \n",
        "\n",
        "    preQues = np.array(self.question_preprocessor.preprocessElem(question))\n",
        "    preQues = tf.convert_to_tensor(preQues)\n",
        "    preQues = tf.expand_dims(preQues, 0)\n",
        "    img_raw = tf.io.read_file(image_path)\n",
        "    img_tensor = tf.image.decode_image(img_raw)\n",
        "    img_tensor = tf.expand_dims(img_tensor, 0)\n",
        "    img_tensor = tf.image.resize_images(img_tensor, [224,224])\n",
        "    ten = resnet(tf.to_float(img_tensor))\n",
        "    res1 = model4(ten,preQues)\n",
        "    res2 = tf.nn.softmax(res1)\n",
        "    argmax = tf.math.argmax(res2, 1).numpy()[0]\n",
        "    answer = self.answer_preprocessor.index2Word[argmax]\n",
        "    \n",
        "    return answer\n",
        "  \n",
        "evaluator = Evaluator(model, question_preprocessor, answer_preprocessor, pretrained_model_path)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model call time 0.061310529708862305\n",
            "0.5809926986694336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'172'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvZ_Wwb_dU_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86e21c3e-cac3-4b44-e564-d1a7ac3ca1e6"
      },
      "source": [
        "def demo():\n",
        "\n",
        "    \n",
        "    print('VQA Demo')\n",
        "    print('Say next to go to next image')\n",
        "    print('Say stop to stop demo')\n",
        "    im_files = []\n",
        "      \n",
        "    i = 0\n",
        "    while(True):\n",
        "        if i == 0 :\n",
        "          print('give an instruction')\n",
        "        else :\n",
        "          print(\"What question would you like to ask?\")\n",
        "        question_str = input()\n",
        "        \n",
        "        if question_str.lower() == 'stop':\n",
        "          clear_output()\n",
        "          print('Bye')\n",
        "          break\n",
        "        elif question_str.lower() == 'live' :\n",
        "          clear_output()\n",
        "          take_photo_live()\n",
        "          im_file = photoPath\n",
        "          i=1\n",
        "          continue\n",
        "        elif question_str.lower() == 'up_im' :\n",
        "          clear_output()\n",
        "          im_file = get_uploaded_image()\n",
        "          print(im_file)\n",
        "          if not im_file or not im_file[-3:] in ['jpg']   : \n",
        "            i == 0\n",
        "            continue\n",
        "          else :\n",
        "            i=1\n",
        "            continue\n",
        "        elif question_str.lower() == 'up_vid' :\n",
        "          i=1\n",
        "          !rm videoPath\n",
        "          im_file = get_uploaded_video()\n",
        "          os.rename(im_file, videoPath)\n",
        "          if not im_file or  not im_file[-3:]  == 'mp4' :\n",
        "            i = 0\n",
        "            continue\n",
        "          else :\n",
        "            #take_photo(im_file)\n",
        "            clear_output()\n",
        "            testphoto()\n",
        "            im_file = photoPath\n",
        "            continue\n",
        "        elif question_str.lower() == 'last_vid' : \n",
        "          clear_output()\n",
        "          exists = os.path.isfile(videoPath)\n",
        "          if exists :\n",
        "            testphoto()\n",
        "            im_file = photoPath\n",
        "            continue\n",
        "          else :\n",
        "            i = 0\n",
        "            continue\n",
        "        elif question_str.lower() =='img' : \n",
        "          clear_output()\n",
        "          print('get image url')\n",
        "          im_file = input()\n",
        "          exists = os.path.isfile(url)\n",
        "         \n",
        "          if not exist or not im_file or not im_file[-3:] in ['jpg']   : \n",
        "            i == 0\n",
        "            continue\n",
        "          else :\n",
        "            i=1\n",
        "\n",
        "        else :\n",
        "          if i == 0 :\n",
        "            clear_output()\n",
        "            continue\n",
        "        \n",
        "        print(evaluator.evaluate(im_file, question_str) )\n",
        "        \n",
        "        \n",
        "        \n",
        "          \n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UPyCH_4xKYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demo()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}